syntax="proto2";

service Speech {
    // Performs synchronous speech recognition: receive results after all audio
    // has been sent and processed.
    rpc Recognize(RecognizeRequest) returns (RecognizeResponse) {
    }

    // Performs bidirectional streaming speech recognition: receive results while
    // sending audio. This method is only available via the gRPC API (not REST).
    rpc StreamingRecognize(stream StreamingRecognizeRequest) returns (RecognizeResponse) {    
    }
    
    rpc EchoTest(RecognizeTest) returns (RecognizeTestEcho) {
    }
}


  // Word-specific information for recognized words.
  message WordInfo {
    // Time offset relative to the beginning of the audio,
    // and corresponding to the start of the spoken word.
    // This field is only set if `enable_word_time_offsets=true` and only
    // in the top hypothesis.
    // This is an experimental feature and the accuracy of the time offset can
    // vary.
    optional int32 start_time = 1;
  
    // Time offset relative to the beginning of the audio,
    // and corresponding to the end of the spoken word.
    // This field is only set if `enable_word_time_offsets=true` and only
    // in the top hypothesis.
    // This is an experimental feature and the accuracy of the time offset can
    // vary.
    optional int32 end_time = 2;
  
    // The word corresponding to this set of information.
    required string word = 3;
  
    // The confidence estimate between 0.0 and 1.0. A higher number
    // indicates an estimated greater likelihood that the recognized words are
    // correct. This field is set only for the top alternative of a non-streaming
    // result or, of a streaming result where `is_final=true`.
    // This field is not guaranteed to be accurate and users should not rely on it
    // to be always provided.
    // The default of 0.0 is a sentinel value indicating `confidence` was not set.
    optional float confidence = 4;
}  

// The top-level message sent by the client for the `Recognize` method.
message RecognizeTest {
    // Required. Provides information to the recognizer that specifies how to
    // process the request.
    required string msg = 1;
}
message RecognizeTestEcho {
    // Required. Provides information to the recognizer that specifies how to
    // process the request.
    required string echo = 1;
}
// The top-level message sent by the client for the `Recognize` method.
message RecognizeRequest {
    // Required. Provides information to the recognizer that specifies how to
    // process the request.
    //required RecognitionConfig config = 1;
    
    // Required. The audio data to be recognized.
    //required RecognitionAudio audio = 2;
    required string data = 1;
}
 
// The only message returned to the client by the `Recognize` method. It
// contains the result as zero or more sequential `SpeechRecognitionResult`
// messages.
message RecognizeResponse {
// Sequential list of transcription results corresponding to
// sequential portions of audio.
//repeated SpeechRecognitionResult results = 2;

// When available, billed audio seconds for the corresponding request.
//optional int32 total_billed_time = 3;
    required string text = 1;
}

message StreamingRecognizeRequest {
    required bytes data = 1;
}

message StreamingRecognizeResponse {
    // Sequential list of transcription results corresponding to
    // sequential portions of audio.
    //repeated SpeechRecognitionResult results = 2;
    
    // When available, billed audio seconds for the corresponding request.
    //optional int32 total_billed_time = 3;
        required string text = 1;
    }
    